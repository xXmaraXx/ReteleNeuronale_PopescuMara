{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-11T11:31:52.292046Z",
     "start_time": "2024-11-11T11:31:49.599935Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "def download_mnist(is_train: bool):\n",
    "    dataset = MNIST(root='./data',\n",
    "                    transform=lambda x: np.array(x).flatten(),\n",
    "                    download=True,\n",
    "                    train=is_train)\n",
    "    mnist_data = []\n",
    "    mnist_labels = []\n",
    "    for image, label in dataset:\n",
    "        mnist_data.append(image)\n",
    "        mnist_labels.append(label)\n",
    "    return np.array(mnist_data), np.array(mnist_labels)\n",
    "train_X, train_Y = download_mnist(True)\n",
    "test_X, test_Y = download_mnist(False)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "15e2943eba8f1c4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:31:54.069790Z",
     "start_time": "2024-11-11T11:31:53.817911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_X = train_X/255.0\n",
    "test_X = test_X/255.0\n",
    "\n",
    "train_Y = np.eye(10)[train_Y]\n",
    "test_Y = np.eye(10)[test_Y]"
   ],
   "id": "838c82c07791f7b6",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4eb19c55f338d260"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:31:55.779210Z",
     "start_time": "2024-11-11T11:31:55.763043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(y):\n",
    "    return y*(1-y)"
   ],
   "id": "cf5c1fe44d38aff4",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7df07c1f59a7524c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:31:57.336707Z",
     "start_time": "2024-11-11T11:31:57.330858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True)) \n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)"
   ],
   "id": "836f9c74e508b58a",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "533d2f859483ce21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:31:58.959713Z",
     "start_time": "2024-11-11T11:31:58.948149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_size = 100\n",
    "\n",
    "np.random.seed(42)\n",
    "W1 = np.random.randn(input_size, hidden_size)*0.01\n",
    "b1 = np.zeros((1,hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size)*0.01\n",
    "b2 = np.zeros((1,output_size))"
   ],
   "id": "2d9d6c69ee82a619",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "783d42f760b2ca2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:32:00.844285Z",
     "start_time": "2024-11-11T11:32:00.830357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward_propagation(X):\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    y1 = sigmoid(z1)\n",
    "    z2 = np.dot(y1, W2) + b2\n",
    "    y2 = softmax(z2)\n",
    "    return y1, z1, y2, z2"
   ],
   "id": "e42e90642d740e9f",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "79c84ee578d1be63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:32:02.767887Z",
     "start_time": "2024-11-11T11:32:02.749622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def backward(X, y_true, y1, y2, learning_rate):\n",
    "    global W1, W2, b1, b2\n",
    "    \n",
    "    output_error = y2-y_true\n",
    "    \n",
    "    hidden_error = np.dot(output_error,W2.T)\n",
    "    hidden_delta = hidden_error*sigmoid_derivative(y1)\n",
    "    \n",
    "    w_hidden_output_gradient = np.dot(y1.T, output_error)\n",
    "    w_input_hidden_gradient = np.dot(X.T,hidden_delta)\n",
    "    \n",
    "    b2_hidden_output_gradient = np.sum(output_error, axis=0, keepdims=True)\n",
    "    b1_input_hidden_gradient = np.sum(hidden_delta, axis=0, keepdims=True)\n",
    "    \n",
    "    W1-=learning_rate*w_input_hidden_gradient\n",
    "    W2-=learning_rate*w_hidden_output_gradient\n",
    "    b1-=learning_rate*b1_input_hidden_gradient\n",
    "    b2-=learning_rate*b2_hidden_output_gradient"
   ],
   "id": "117fd2f848156529",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "19c88b3708127fd7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:32:04.710136Z",
     "start_time": "2024-11-11T11:32:04.703994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cross_entropy_loss(y_pred, y_true, epsilon=1e-12):\n",
    "    m = y_true.shape[0]  \n",
    "    y_pred = np.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    log_likelihood = -np.log(y_pred[range(m), np.argmax(y_true, axis=1)])\n",
    "    loss = np.sum(log_likelihood) / m\n",
    "    return loss\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    return np.mean(np.argmax(y_pred, axis=1) == np.argmax(y_true, axis=1))"
   ],
   "id": "d8f7a6d30d87bfa6",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "653c82b281eb75e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "abef380a1a09c767"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:30:18.493993Z",
     "start_time": "2024-11-11T11:24:12.558773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(train_X, train_Y, test_X, test_Y, epochs=20, batch_size=64, learning_rate=0.05):\n",
    "    n_samples = train_X.shape[0]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        permutation = np.random.permutation(n_samples)\n",
    "        train_X_shuffled = train_X[permutation]\n",
    "        train_Y_shuffled = train_Y[permutation]\n",
    "\n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            X_batch = train_X_shuffled[i:i+batch_size]\n",
    "            Y_batch = train_Y_shuffled[i:i+batch_size]\n",
    "\n",
    "            y1, z1, y2, z2 = forward_propagation(X_batch)\n",
    "\n",
    "            backward(X_batch, Y_batch, y1, y2, learning_rate)\n",
    "\n",
    "        _, _, _, val_pred_train = forward_propagation(train_X)\n",
    "        train_acc = accuracy(val_pred_train, train_Y)\n",
    "        _, _, _, val_pred = forward_propagation(test_X)\n",
    "        val_loss = cross_entropy_loss(val_pred, test_Y)\n",
    "        val_acc = accuracy(val_pred, test_Y)\n",
    "        \n",
    "        \n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs},Train Accuracy: {train_acc:.4f} ,Loss: {val_loss:.4f} ,Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "train(train_X, train_Y, test_X, test_Y, epochs=120, batch_size=100, learning_rate=0.01)"
   ],
   "id": "8523972cc4eb76dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/135,Train Accuracy: 0.9266 ,Loss: 0.0693 ,Validation Accuracy: 0.9293\n",
      "Epoch 2/135,Train Accuracy: 0.9502 ,Loss: 0.0350 ,Validation Accuracy: 0.9472\n",
      "Epoch 3/135,Train Accuracy: 0.9597 ,Loss: 0.0238 ,Validation Accuracy: 0.9561\n",
      "Epoch 4/135,Train Accuracy: 0.9672 ,Loss: 0.0207 ,Validation Accuracy: 0.9626\n",
      "Epoch 5/135,Train Accuracy: 0.9721 ,Loss: 0.0200 ,Validation Accuracy: 0.9653\n",
      "Epoch 6/135,Train Accuracy: 0.9767 ,Loss: 0.0118 ,Validation Accuracy: 0.9704\n",
      "Epoch 7/135,Train Accuracy: 0.9809 ,Loss: 0.0118 ,Validation Accuracy: 0.9721\n",
      "Epoch 8/135,Train Accuracy: 0.9815 ,Loss: 0.0142 ,Validation Accuracy: 0.9719\n",
      "Epoch 9/135,Train Accuracy: 0.9832 ,Loss: 0.0114 ,Validation Accuracy: 0.9738\n",
      "Epoch 10/135,Train Accuracy: 0.9857 ,Loss: 0.0115 ,Validation Accuracy: 0.9752\n",
      "Epoch 11/135,Train Accuracy: 0.9874 ,Loss: 0.0140 ,Validation Accuracy: 0.9765\n",
      "Epoch 12/135,Train Accuracy: 0.9885 ,Loss: 0.0141 ,Validation Accuracy: 0.9760\n",
      "Epoch 13/135,Train Accuracy: 0.9911 ,Loss: 0.0113 ,Validation Accuracy: 0.9779\n",
      "Epoch 14/135,Train Accuracy: 0.9914 ,Loss: 0.0113 ,Validation Accuracy: 0.9774\n",
      "Epoch 15/135,Train Accuracy: 0.9918 ,Loss: 0.0111 ,Validation Accuracy: 0.9775\n",
      "Epoch 16/135,Train Accuracy: 0.9938 ,Loss: 0.0114 ,Validation Accuracy: 0.9783\n",
      "Epoch 17/135,Train Accuracy: 0.9938 ,Loss: 0.0113 ,Validation Accuracy: 0.9780\n",
      "Epoch 18/135,Train Accuracy: 0.9945 ,Loss: 0.0112 ,Validation Accuracy: 0.9782\n",
      "Epoch 19/135,Train Accuracy: 0.9955 ,Loss: 0.0114 ,Validation Accuracy: 0.9791\n",
      "Epoch 20/135,Train Accuracy: 0.9962 ,Loss: 0.0141 ,Validation Accuracy: 0.9790\n",
      "Epoch 21/135,Train Accuracy: 0.9967 ,Loss: 0.0116 ,Validation Accuracy: 0.9780\n",
      "Epoch 22/135,Train Accuracy: 0.9974 ,Loss: 0.0140 ,Validation Accuracy: 0.9796\n",
      "Epoch 23/135,Train Accuracy: 0.9978 ,Loss: 0.0142 ,Validation Accuracy: 0.9794\n",
      "Epoch 24/135,Train Accuracy: 0.9970 ,Loss: 0.0167 ,Validation Accuracy: 0.9782\n",
      "Epoch 25/135,Train Accuracy: 0.9981 ,Loss: 0.0167 ,Validation Accuracy: 0.9794\n",
      "Epoch 26/135,Train Accuracy: 0.9975 ,Loss: 0.0141 ,Validation Accuracy: 0.9784\n",
      "Epoch 27/135,Train Accuracy: 0.9986 ,Loss: 0.0144 ,Validation Accuracy: 0.9779\n",
      "Epoch 28/135,Train Accuracy: 0.9986 ,Loss: 0.0167 ,Validation Accuracy: 0.9796\n",
      "Epoch 29/135,Train Accuracy: 0.9990 ,Loss: 0.0167 ,Validation Accuracy: 0.9798\n",
      "Epoch 30/135,Train Accuracy: 0.9990 ,Loss: 0.0140 ,Validation Accuracy: 0.9798\n",
      "Epoch 31/135,Train Accuracy: 0.9991 ,Loss: 0.0142 ,Validation Accuracy: 0.9789\n",
      "Epoch 32/135,Train Accuracy: 0.9993 ,Loss: 0.0168 ,Validation Accuracy: 0.9797\n",
      "Epoch 33/135,Train Accuracy: 0.9993 ,Loss: 0.0144 ,Validation Accuracy: 0.9787\n",
      "Epoch 34/135,Train Accuracy: 0.9995 ,Loss: 0.0141 ,Validation Accuracy: 0.9801\n",
      "Epoch 35/135,Train Accuracy: 0.9995 ,Loss: 0.0168 ,Validation Accuracy: 0.9801\n",
      "Epoch 36/135,Train Accuracy: 0.9996 ,Loss: 0.0144 ,Validation Accuracy: 0.9791\n",
      "Epoch 37/135,Train Accuracy: 0.9997 ,Loss: 0.0142 ,Validation Accuracy: 0.9793\n",
      "Epoch 38/135,Train Accuracy: 0.9997 ,Loss: 0.0145 ,Validation Accuracy: 0.9785\n",
      "Epoch 39/135,Train Accuracy: 0.9998 ,Loss: 0.0168 ,Validation Accuracy: 0.9789\n",
      "Epoch 40/135,Train Accuracy: 0.9998 ,Loss: 0.0195 ,Validation Accuracy: 0.9794\n",
      "Epoch 41/135,Train Accuracy: 0.9998 ,Loss: 0.0142 ,Validation Accuracy: 0.9797\n",
      "Epoch 42/135,Train Accuracy: 0.9999 ,Loss: 0.0194 ,Validation Accuracy: 0.9788\n",
      "Epoch 43/135,Train Accuracy: 0.9998 ,Loss: 0.0168 ,Validation Accuracy: 0.9791\n",
      "Epoch 44/135,Train Accuracy: 0.9999 ,Loss: 0.0194 ,Validation Accuracy: 0.9787\n",
      "Epoch 45/135,Train Accuracy: 0.9999 ,Loss: 0.0171 ,Validation Accuracy: 0.9793\n",
      "Epoch 46/135,Train Accuracy: 0.9999 ,Loss: 0.0194 ,Validation Accuracy: 0.9792\n",
      "Epoch 47/135,Train Accuracy: 0.9999 ,Loss: 0.0194 ,Validation Accuracy: 0.9791\n",
      "Epoch 48/135,Train Accuracy: 0.9999 ,Loss: 0.0169 ,Validation Accuracy: 0.9795\n",
      "Epoch 49/135,Train Accuracy: 0.9999 ,Loss: 0.0169 ,Validation Accuracy: 0.9788\n",
      "Epoch 50/135,Train Accuracy: 0.9999 ,Loss: 0.0169 ,Validation Accuracy: 0.9791\n",
      "Epoch 51/135,Train Accuracy: 1.0000 ,Loss: 0.0171 ,Validation Accuracy: 0.9790\n",
      "Epoch 52/135,Train Accuracy: 0.9999 ,Loss: 0.0148 ,Validation Accuracy: 0.9791\n",
      "Epoch 53/135,Train Accuracy: 1.0000 ,Loss: 0.0144 ,Validation Accuracy: 0.9789\n",
      "Epoch 54/135,Train Accuracy: 1.0000 ,Loss: 0.0145 ,Validation Accuracy: 0.9791\n",
      "Epoch 55/135,Train Accuracy: 1.0000 ,Loss: 0.0148 ,Validation Accuracy: 0.9790\n",
      "Epoch 56/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9792\n",
      "Epoch 57/135,Train Accuracy: 1.0000 ,Loss: 0.0168 ,Validation Accuracy: 0.9791\n",
      "Epoch 58/135,Train Accuracy: 1.0000 ,Loss: 0.0168 ,Validation Accuracy: 0.9793\n",
      "Epoch 59/135,Train Accuracy: 1.0000 ,Loss: 0.0168 ,Validation Accuracy: 0.9793\n",
      "Epoch 60/135,Train Accuracy: 1.0000 ,Loss: 0.0169 ,Validation Accuracy: 0.9791\n",
      "Epoch 61/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9793\n",
      "Epoch 62/135,Train Accuracy: 1.0000 ,Loss: 0.0168 ,Validation Accuracy: 0.9791\n",
      "Epoch 63/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9789\n",
      "Epoch 64/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9790\n",
      "Epoch 65/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9788\n",
      "Epoch 66/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9790\n",
      "Epoch 67/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9788\n",
      "Epoch 68/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9791\n",
      "Epoch 69/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9788\n",
      "Epoch 70/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9791\n",
      "Epoch 71/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9789\n",
      "Epoch 72/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9788\n",
      "Epoch 73/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9794\n",
      "Epoch 74/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9788\n",
      "Epoch 75/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9790\n",
      "Epoch 76/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9794\n",
      "Epoch 77/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9792\n",
      "Epoch 78/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9793\n",
      "Epoch 79/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9796\n",
      "Epoch 80/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9791\n",
      "Epoch 81/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9791\n",
      "Epoch 82/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9790\n",
      "Epoch 83/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9790\n",
      "Epoch 84/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9793\n",
      "Epoch 85/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9788\n",
      "Epoch 86/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9790\n",
      "Epoch 87/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9787\n",
      "Epoch 88/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9787\n",
      "Epoch 89/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9789\n",
      "Epoch 90/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9788\n",
      "Epoch 91/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9792\n",
      "Epoch 92/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9790\n",
      "Epoch 93/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9792\n",
      "Epoch 94/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9793\n",
      "Epoch 95/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9794\n",
      "Epoch 96/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9789\n",
      "Epoch 97/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9790\n",
      "Epoch 98/135,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9791\n",
      "Epoch 99/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9793\n",
      "Epoch 100/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9788\n",
      "Epoch 101/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9789\n",
      "Epoch 102/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9792\n",
      "Epoch 103/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9789\n",
      "Epoch 104/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9791\n",
      "Epoch 105/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9790\n",
      "Epoch 106/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9792\n",
      "Epoch 107/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9789\n",
      "Epoch 108/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9793\n",
      "Epoch 109/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9791\n",
      "Epoch 110/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9793\n",
      "Epoch 111/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9792\n",
      "Epoch 112/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9789\n",
      "Epoch 113/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9791\n",
      "Epoch 114/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9792\n",
      "Epoch 115/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9793\n",
      "Epoch 116/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9792\n",
      "Epoch 117/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9791\n",
      "Epoch 118/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9792\n",
      "Epoch 119/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9791\n",
      "Epoch 120/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9792\n",
      "Epoch 121/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9790\n",
      "Epoch 122/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9793\n",
      "Epoch 123/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9791\n",
      "Epoch 124/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9792\n",
      "Epoch 125/135,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9793\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 27\u001B[0m\n\u001B[0;32m     21\u001B[0m         val_acc \u001B[38;5;241m=\u001B[39m accuracy(val_pred, test_Y)\n\u001B[0;32m     25\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,Train Accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_acc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m ,Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mval_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m ,Validation Accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mval_acc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 27\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_X\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_Y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_X\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_Y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m135\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[13], line 15\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(train_X, train_Y, test_X, test_Y, epochs, batch_size, learning_rate)\u001B[0m\n\u001B[0;32m     11\u001B[0m     Y_batch \u001B[38;5;241m=\u001B[39m train_Y_shuffled[i:i\u001B[38;5;241m+\u001B[39mbatch_size]\n\u001B[0;32m     13\u001B[0m     y1, z1, y2, z2 \u001B[38;5;241m=\u001B[39m forward_propagation(X_batch)\n\u001B[1;32m---> 15\u001B[0m     \u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m _, _, _, val_pred_train \u001B[38;5;241m=\u001B[39m forward_propagation(train_X)\n\u001B[0;32m     18\u001B[0m train_acc \u001B[38;5;241m=\u001B[39m accuracy(val_pred_train, train_Y)\n",
      "Cell \u001B[1;32mIn[7], line 10\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(X, y_true, y1, y2, learning_rate)\u001B[0m\n\u001B[0;32m      7\u001B[0m hidden_delta \u001B[38;5;241m=\u001B[39m hidden_error\u001B[38;5;241m*\u001B[39msigmoid_derivative(y1)\n\u001B[0;32m      9\u001B[0m w_hidden_output_gradient \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(y1\u001B[38;5;241m.\u001B[39mT, output_error)\n\u001B[1;32m---> 10\u001B[0m w_input_hidden_gradient \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43mhidden_delta\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m b2_hidden_output_gradient \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum(output_error, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     13\u001B[0m b1_input_hidden_gradient \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum(hidden_delta, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "dff8b410dad9547c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:38:07.319733Z",
     "start_time": "2024-11-11T11:32:07.405764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_with_learning_rate_scheduler(train_X, train_Y, test_X, test_Y, epochs=20, batch_size=64, learning_rate=0.05):\n",
    "    n_samples = train_X.shape[0]\n",
    "    learning_rates_acc = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        permutation = np.random.permutation(n_samples)\n",
    "        train_X_shuffled = train_X[permutation]\n",
    "        train_Y_shuffled = train_Y[permutation]\n",
    "\n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            X_batch = train_X_shuffled[i:i+batch_size]\n",
    "            Y_batch = train_Y_shuffled[i:i+batch_size]\n",
    "\n",
    "            y1, z1, y2, z2 = forward_propagation(X_batch)\n",
    "\n",
    "            backward(X_batch, Y_batch, y1, y2, learning_rate)\n",
    "\n",
    "        _, _, _, val_pred_train = forward_propagation(train_X)\n",
    "        train_acc = accuracy(val_pred_train, train_Y)\n",
    "        _, _, _, val_pred = forward_propagation(test_X)\n",
    "        val_loss = cross_entropy_loss(val_pred, test_Y)\n",
    "        val_acc = accuracy(val_pred, test_Y)\n",
    "        learning_rates_acc.append(val_acc)\n",
    "        \n",
    "        if epoch % 10==0:\n",
    "            if abs(learning_rates_acc[-1] - np.mean(learning_rates_acc[-11:-1])) < 0.01:\n",
    "                learning_rate = learning_rate/1.05\n",
    "                print(\"New learning rate:\", learning_rate)\n",
    "        \n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs},Train Accuracy: {train_acc:.4f} ,Loss: {val_loss:.4f} ,Validation Accuracy: {val_acc:.4f}, Learning Rate: {learning_rate:.5f}\")\n",
    "\n",
    "train_with_learning_rate_scheduler(train_X, train_Y, test_X, test_Y, epochs=120, batch_size=100, learning_rate=0.01)"
   ],
   "id": "c432905bd69b507d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120,Train Accuracy: 0.9266 ,Loss: 0.0693 ,Validation Accuracy: 0.9293, Learning Rate: 0.01000\n",
      "Epoch 2/120,Train Accuracy: 0.9502 ,Loss: 0.0350 ,Validation Accuracy: 0.9472, Learning Rate: 0.01000\n",
      "Epoch 3/120,Train Accuracy: 0.9597 ,Loss: 0.0238 ,Validation Accuracy: 0.9561, Learning Rate: 0.01000\n",
      "Epoch 4/120,Train Accuracy: 0.9672 ,Loss: 0.0207 ,Validation Accuracy: 0.9626, Learning Rate: 0.01000\n",
      "Epoch 5/120,Train Accuracy: 0.9721 ,Loss: 0.0200 ,Validation Accuracy: 0.9653, Learning Rate: 0.01000\n",
      "Epoch 6/120,Train Accuracy: 0.9767 ,Loss: 0.0118 ,Validation Accuracy: 0.9704, Learning Rate: 0.01000\n",
      "Epoch 7/120,Train Accuracy: 0.9809 ,Loss: 0.0118 ,Validation Accuracy: 0.9721, Learning Rate: 0.01000\n",
      "Epoch 8/120,Train Accuracy: 0.9815 ,Loss: 0.0142 ,Validation Accuracy: 0.9719, Learning Rate: 0.01000\n",
      "Epoch 9/120,Train Accuracy: 0.9832 ,Loss: 0.0114 ,Validation Accuracy: 0.9738, Learning Rate: 0.01000\n",
      "Epoch 10/120,Train Accuracy: 0.9857 ,Loss: 0.0115 ,Validation Accuracy: 0.9752, Learning Rate: 0.01000\n",
      "Epoch 11/120,Train Accuracy: 0.9874 ,Loss: 0.0140 ,Validation Accuracy: 0.9765, Learning Rate: 0.01000\n",
      "Epoch 12/120,Train Accuracy: 0.9885 ,Loss: 0.0141 ,Validation Accuracy: 0.9760, Learning Rate: 0.01000\n",
      "Epoch 13/120,Train Accuracy: 0.9911 ,Loss: 0.0113 ,Validation Accuracy: 0.9779, Learning Rate: 0.01000\n",
      "Epoch 14/120,Train Accuracy: 0.9914 ,Loss: 0.0113 ,Validation Accuracy: 0.9774, Learning Rate: 0.01000\n",
      "Epoch 15/120,Train Accuracy: 0.9918 ,Loss: 0.0111 ,Validation Accuracy: 0.9775, Learning Rate: 0.01000\n",
      "Epoch 16/120,Train Accuracy: 0.9938 ,Loss: 0.0114 ,Validation Accuracy: 0.9783, Learning Rate: 0.01000\n",
      "Epoch 17/120,Train Accuracy: 0.9938 ,Loss: 0.0113 ,Validation Accuracy: 0.9780, Learning Rate: 0.01000\n",
      "Epoch 18/120,Train Accuracy: 0.9945 ,Loss: 0.0112 ,Validation Accuracy: 0.9782, Learning Rate: 0.01000\n",
      "Epoch 19/120,Train Accuracy: 0.9955 ,Loss: 0.0114 ,Validation Accuracy: 0.9791, Learning Rate: 0.01000\n",
      "Epoch 20/120,Train Accuracy: 0.9962 ,Loss: 0.0141 ,Validation Accuracy: 0.9790, Learning Rate: 0.01000\n",
      "New learning rate: 0.009523809523809523\n",
      "Epoch 21/120,Train Accuracy: 0.9967 ,Loss: 0.0116 ,Validation Accuracy: 0.9780, Learning Rate: 0.00952\n",
      "Epoch 22/120,Train Accuracy: 0.9976 ,Loss: 0.0140 ,Validation Accuracy: 0.9797, Learning Rate: 0.00952\n",
      "Epoch 23/120,Train Accuracy: 0.9978 ,Loss: 0.0142 ,Validation Accuracy: 0.9796, Learning Rate: 0.00952\n",
      "Epoch 24/120,Train Accuracy: 0.9971 ,Loss: 0.0167 ,Validation Accuracy: 0.9782, Learning Rate: 0.00952\n",
      "Epoch 25/120,Train Accuracy: 0.9981 ,Loss: 0.0167 ,Validation Accuracy: 0.9797, Learning Rate: 0.00952\n",
      "Epoch 26/120,Train Accuracy: 0.9976 ,Loss: 0.0141 ,Validation Accuracy: 0.9784, Learning Rate: 0.00952\n",
      "Epoch 27/120,Train Accuracy: 0.9986 ,Loss: 0.0143 ,Validation Accuracy: 0.9779, Learning Rate: 0.00952\n",
      "Epoch 28/120,Train Accuracy: 0.9985 ,Loss: 0.0167 ,Validation Accuracy: 0.9796, Learning Rate: 0.00952\n",
      "Epoch 29/120,Train Accuracy: 0.9990 ,Loss: 0.0167 ,Validation Accuracy: 0.9799, Learning Rate: 0.00952\n",
      "Epoch 30/120,Train Accuracy: 0.9990 ,Loss: 0.0140 ,Validation Accuracy: 0.9798, Learning Rate: 0.00952\n",
      "New learning rate: 0.009070294784580497\n",
      "Epoch 31/120,Train Accuracy: 0.9990 ,Loss: 0.0142 ,Validation Accuracy: 0.9791, Learning Rate: 0.00907\n",
      "Epoch 32/120,Train Accuracy: 0.9993 ,Loss: 0.0168 ,Validation Accuracy: 0.9796, Learning Rate: 0.00907\n",
      "Epoch 33/120,Train Accuracy: 0.9992 ,Loss: 0.0144 ,Validation Accuracy: 0.9788, Learning Rate: 0.00907\n",
      "Epoch 34/120,Train Accuracy: 0.9994 ,Loss: 0.0141 ,Validation Accuracy: 0.9800, Learning Rate: 0.00907\n",
      "Epoch 35/120,Train Accuracy: 0.9995 ,Loss: 0.0168 ,Validation Accuracy: 0.9801, Learning Rate: 0.00907\n",
      "Epoch 36/120,Train Accuracy: 0.9996 ,Loss: 0.0144 ,Validation Accuracy: 0.9792, Learning Rate: 0.00907\n",
      "Epoch 37/120,Train Accuracy: 0.9997 ,Loss: 0.0142 ,Validation Accuracy: 0.9794, Learning Rate: 0.00907\n",
      "Epoch 38/120,Train Accuracy: 0.9996 ,Loss: 0.0144 ,Validation Accuracy: 0.9786, Learning Rate: 0.00907\n",
      "Epoch 39/120,Train Accuracy: 0.9997 ,Loss: 0.0168 ,Validation Accuracy: 0.9792, Learning Rate: 0.00907\n",
      "Epoch 40/120,Train Accuracy: 0.9998 ,Loss: 0.0171 ,Validation Accuracy: 0.9796, Learning Rate: 0.00907\n",
      "New learning rate: 0.008638375985314759\n",
      "Epoch 41/120,Train Accuracy: 0.9998 ,Loss: 0.0142 ,Validation Accuracy: 0.9798, Learning Rate: 0.00864\n",
      "Epoch 42/120,Train Accuracy: 0.9998 ,Loss: 0.0194 ,Validation Accuracy: 0.9790, Learning Rate: 0.00864\n",
      "Epoch 43/120,Train Accuracy: 0.9998 ,Loss: 0.0168 ,Validation Accuracy: 0.9793, Learning Rate: 0.00864\n",
      "Epoch 44/120,Train Accuracy: 0.9999 ,Loss: 0.0171 ,Validation Accuracy: 0.9789, Learning Rate: 0.00864\n",
      "Epoch 45/120,Train Accuracy: 0.9999 ,Loss: 0.0170 ,Validation Accuracy: 0.9795, Learning Rate: 0.00864\n",
      "Epoch 46/120,Train Accuracy: 0.9999 ,Loss: 0.0194 ,Validation Accuracy: 0.9793, Learning Rate: 0.00864\n",
      "Epoch 47/120,Train Accuracy: 0.9999 ,Loss: 0.0194 ,Validation Accuracy: 0.9792, Learning Rate: 0.00864\n",
      "Epoch 48/120,Train Accuracy: 0.9999 ,Loss: 0.0194 ,Validation Accuracy: 0.9795, Learning Rate: 0.00864\n",
      "Epoch 49/120,Train Accuracy: 0.9999 ,Loss: 0.0194 ,Validation Accuracy: 0.9787, Learning Rate: 0.00864\n",
      "Epoch 50/120,Train Accuracy: 0.9999 ,Loss: 0.0170 ,Validation Accuracy: 0.9791, Learning Rate: 0.00864\n",
      "New learning rate: 0.008227024747918818\n",
      "Epoch 51/120,Train Accuracy: 1.0000 ,Loss: 0.0169 ,Validation Accuracy: 0.9788, Learning Rate: 0.00823\n",
      "Epoch 52/120,Train Accuracy: 0.9999 ,Loss: 0.0170 ,Validation Accuracy: 0.9791, Learning Rate: 0.00823\n",
      "Epoch 53/120,Train Accuracy: 0.9999 ,Loss: 0.0170 ,Validation Accuracy: 0.9790, Learning Rate: 0.00823\n",
      "Epoch 54/120,Train Accuracy: 1.0000 ,Loss: 0.0146 ,Validation Accuracy: 0.9792, Learning Rate: 0.00823\n",
      "Epoch 55/120,Train Accuracy: 1.0000 ,Loss: 0.0170 ,Validation Accuracy: 0.9789, Learning Rate: 0.00823\n",
      "Epoch 56/120,Train Accuracy: 0.9999 ,Loss: 0.0168 ,Validation Accuracy: 0.9795, Learning Rate: 0.00823\n",
      "Epoch 57/120,Train Accuracy: 1.0000 ,Loss: 0.0170 ,Validation Accuracy: 0.9790, Learning Rate: 0.00823\n",
      "Epoch 58/120,Train Accuracy: 1.0000 ,Loss: 0.0168 ,Validation Accuracy: 0.9794, Learning Rate: 0.00823\n",
      "Epoch 59/120,Train Accuracy: 1.0000 ,Loss: 0.0168 ,Validation Accuracy: 0.9793, Learning Rate: 0.00823\n",
      "Epoch 60/120,Train Accuracy: 1.0000 ,Loss: 0.0194 ,Validation Accuracy: 0.9792, Learning Rate: 0.00823\n",
      "New learning rate: 0.007835261664684588\n",
      "Epoch 61/120,Train Accuracy: 1.0000 ,Loss: 0.0168 ,Validation Accuracy: 0.9793, Learning Rate: 0.00784\n",
      "Epoch 62/120,Train Accuracy: 1.0000 ,Loss: 0.0168 ,Validation Accuracy: 0.9790, Learning Rate: 0.00784\n",
      "Epoch 63/120,Train Accuracy: 1.0000 ,Loss: 0.0168 ,Validation Accuracy: 0.9791, Learning Rate: 0.00784\n",
      "Epoch 64/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9789, Learning Rate: 0.00784\n",
      "Epoch 65/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9791, Learning Rate: 0.00784\n",
      "Epoch 66/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9789, Learning Rate: 0.00784\n",
      "Epoch 67/120,Train Accuracy: 1.0000 ,Loss: 0.0168 ,Validation Accuracy: 0.9789, Learning Rate: 0.00784\n",
      "Epoch 68/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9790, Learning Rate: 0.00784\n",
      "Epoch 69/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9787, Learning Rate: 0.00784\n",
      "Epoch 70/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9792, Learning Rate: 0.00784\n",
      "New learning rate: 0.007462153966366274\n",
      "Epoch 71/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9788, Learning Rate: 0.00746\n",
      "Epoch 72/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9788, Learning Rate: 0.00746\n",
      "Epoch 73/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9794, Learning Rate: 0.00746\n",
      "Epoch 74/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9790, Learning Rate: 0.00746\n",
      "Epoch 75/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9791, Learning Rate: 0.00746\n",
      "Epoch 76/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9795, Learning Rate: 0.00746\n",
      "Epoch 77/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9789, Learning Rate: 0.00746\n",
      "Epoch 78/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9791, Learning Rate: 0.00746\n",
      "Epoch 79/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9794, Learning Rate: 0.00746\n",
      "Epoch 80/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9791, Learning Rate: 0.00746\n",
      "New learning rate: 0.007106813301301213\n",
      "Epoch 81/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9793, Learning Rate: 0.00711\n",
      "Epoch 82/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9789, Learning Rate: 0.00711\n",
      "Epoch 83/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9791, Learning Rate: 0.00711\n",
      "Epoch 84/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9795, Learning Rate: 0.00711\n",
      "Epoch 85/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9787, Learning Rate: 0.00711\n",
      "Epoch 86/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9789, Learning Rate: 0.00711\n",
      "Epoch 87/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9788, Learning Rate: 0.00711\n",
      "Epoch 88/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9789, Learning Rate: 0.00711\n",
      "Epoch 89/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9789, Learning Rate: 0.00711\n",
      "Epoch 90/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9789, Learning Rate: 0.00711\n",
      "New learning rate: 0.00676839362028687\n",
      "Epoch 91/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9789, Learning Rate: 0.00677\n",
      "Epoch 92/120,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9791, Learning Rate: 0.00677\n",
      "Epoch 93/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9788, Learning Rate: 0.00677\n",
      "Epoch 94/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9793, Learning Rate: 0.00677\n",
      "Epoch 95/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9793, Learning Rate: 0.00677\n",
      "Epoch 96/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9789, Learning Rate: 0.00677\n",
      "Epoch 97/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9790, Learning Rate: 0.00677\n",
      "Epoch 98/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9793, Learning Rate: 0.00677\n",
      "Epoch 99/120,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9793, Learning Rate: 0.00677\n",
      "Epoch 100/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9786, Learning Rate: 0.00677\n",
      "New learning rate: 0.006446089162177971\n",
      "Epoch 101/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9789, Learning Rate: 0.00645\n",
      "Epoch 102/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9791, Learning Rate: 0.00645\n",
      "Epoch 103/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9787, Learning Rate: 0.00645\n",
      "Epoch 104/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9793, Learning Rate: 0.00645\n",
      "Epoch 105/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9789, Learning Rate: 0.00645\n",
      "Epoch 106/120,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9792, Learning Rate: 0.00645\n",
      "Epoch 107/120,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9790, Learning Rate: 0.00645\n",
      "Epoch 108/120,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9792, Learning Rate: 0.00645\n",
      "Epoch 109/120,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9791, Learning Rate: 0.00645\n",
      "Epoch 110/120,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9791, Learning Rate: 0.00645\n",
      "New learning rate: 0.006139132535407591\n",
      "Epoch 111/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9794, Learning Rate: 0.00614\n",
      "Epoch 112/120,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9789, Learning Rate: 0.00614\n",
      "Epoch 113/120,Train Accuracy: 1.0000 ,Loss: 0.0167 ,Validation Accuracy: 0.9791, Learning Rate: 0.00614\n",
      "Epoch 114/120,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9793, Learning Rate: 0.00614\n",
      "Epoch 115/120,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9790, Learning Rate: 0.00614\n",
      "Epoch 116/120,Train Accuracy: 1.0000 ,Loss: 0.0166 ,Validation Accuracy: 0.9791, Learning Rate: 0.00614\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 33\u001B[0m\n\u001B[0;32m     28\u001B[0m                 \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNew learning rate:\u001B[39m\u001B[38;5;124m\"\u001B[39m, learning_rate)\n\u001B[0;32m     31\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,Train Accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_acc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m ,Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mval_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m ,Validation Accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mval_acc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Learning Rate: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlearning_rate\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.5f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 33\u001B[0m \u001B[43mtrain_with_learning_rate_scheduler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_X\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_Y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_X\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_Y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m120\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[28], line 14\u001B[0m, in \u001B[0;36mtrain_with_learning_rate_scheduler\u001B[1;34m(train_X, train_Y, test_X, test_Y, epochs, batch_size, learning_rate)\u001B[0m\n\u001B[0;32m     11\u001B[0m     X_batch \u001B[38;5;241m=\u001B[39m train_X_shuffled[i:i\u001B[38;5;241m+\u001B[39mbatch_size]\n\u001B[0;32m     12\u001B[0m     Y_batch \u001B[38;5;241m=\u001B[39m train_Y_shuffled[i:i\u001B[38;5;241m+\u001B[39mbatch_size]\n\u001B[1;32m---> 14\u001B[0m     y1, z1, y2, z2 \u001B[38;5;241m=\u001B[39m \u001B[43mforward_propagation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m     backward(X_batch, Y_batch, y1, y2, learning_rate)\n\u001B[0;32m     18\u001B[0m _, _, _, val_pred_train \u001B[38;5;241m=\u001B[39m forward_propagation(train_X)\n",
      "Cell \u001B[1;32mIn[25], line 3\u001B[0m, in \u001B[0;36mforward_propagation\u001B[1;34m(X)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward_propagation\u001B[39m(X):\n\u001B[0;32m      2\u001B[0m     z1 \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(X, W1) \u001B[38;5;241m+\u001B[39m b1\n\u001B[1;32m----> 3\u001B[0m     y1 \u001B[38;5;241m=\u001B[39m \u001B[43msigmoid\u001B[49m\u001B[43m(\u001B[49m\u001B[43mz1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     z2 \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(y1, W2) \u001B[38;5;241m+\u001B[39m b2\n\u001B[0;32m      5\u001B[0m     y2 \u001B[38;5;241m=\u001B[39m softmax(z2)\n",
      "Cell \u001B[1;32mIn[22], line 2\u001B[0m, in \u001B[0;36msigmoid\u001B[1;34m(z)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msigmoid\u001B[39m(z):\n\u001B[1;32m----> 2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m1\u001B[39m\u001B[38;5;241m/\u001B[39m(\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexp\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43mz\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
