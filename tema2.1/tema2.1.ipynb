{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-20T13:56:44.887220Z",
     "start_time": "2024-10-20T13:56:43.049725Z"
    }
   },
   "source": [
    "from itertools import permutations\n",
    "\n",
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "def download_mnist(is_train: bool):\n",
    "    dataset = MNIST(root='./data',\n",
    "                    transform=lambda x: np.array(x).flatten(),\n",
    "                    download=True,\n",
    "                    train=is_train)\n",
    "    mnist_data = []\n",
    "    mnist_labels = []\n",
    "    for image, label in dataset:\n",
    "        mnist_data.append(image)\n",
    "        mnist_labels.append(label)\n",
    "    return np.array(mnist_data), np.array(mnist_labels)\n",
    "    \n",
    "train_X, train_Y = download_mnist(True)\n",
    "test_X, test_Y = download_mnist(False)"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T13:10:23.789007Z",
     "start_time": "2024-10-20T13:10:23.784479Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_Y.shape[0])",
   "id": "82824cb3e151f6fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T13:56:47.301383Z",
     "start_time": "2024-10-20T13:56:47.123209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#AICI NORMALIZEZ \n",
    "train_X = train_X/255.0\n",
    "test_X = test_X/255.0\n",
    "\n",
    "#ONE HOT ENCODE\n",
    "train_Y = np.eye(10)[train_Y]\n",
    "test_Y = np.eye(10)[test_Y]\n"
   ],
   "id": "ed8a6c07f40d175d",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T13:56:57.731688Z",
     "start_time": "2024-10-20T13:56:57.725214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True)) \n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)"
   ],
   "id": "6a5a29be728ef094",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T13:56:59.487554Z",
     "start_time": "2024-10-20T13:56:59.483494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward_propagation(X, W, b):\n",
    "    z = np.dot(X, W) + b\n",
    "    return softmax(z)\n",
    "    "
   ],
   "id": "d6aea07fd3078b08",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T13:57:00.958742Z",
     "start_time": "2024-10-20T13:57:00.953156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def backward_propagation(X, Y, W, b, learning_rate, y_predict):\n",
    "    error = Y - y_predict\n",
    "    update = np.dot(X.T, error ) * learning_rate\n",
    "    W += update\n",
    "    b += np.sum(error, axis=0)*learning_rate\n",
    "    return W, b"
   ],
   "id": "4ad0e3336a6ccee5",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T13:57:02.684717Z",
     "start_time": "2024-10-20T13:57:02.680305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def accuracy(y_predict, y_true):\n",
    "    return np.mean(np.argmax(y_predict, axis=1) == np.argmax(y_true, axis=1))"
   ],
   "id": "450dd15dfa36aa7e",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T13:57:42.978369Z",
     "start_time": "2024-10-20T13:57:04.142879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(train_X, train_Y, test_X, test_Y, epochs, learning_rate, batch_size):\n",
    "    np.random.seed(42)\n",
    "    weights = np.random.randn(train_X.shape[1], 10)*0.01\n",
    "    bias = np.zeros((10 ,))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        permutations = np.random.permutation(train_X.shape[0])\n",
    "        train_X_shuffled = train_X[permutations]\n",
    "        train_Y_shuffled = train_Y[permutations]\n",
    "        \n",
    "        for i in range(0, train_X_shuffled.shape[0], batch_size):\n",
    "            X_batch = train_X_shuffled[i:i+batch_size]\n",
    "            Y_batch = train_Y_shuffled[i:i+batch_size]\n",
    "            \n",
    "            y_predict = forward_propagation(X_batch, weights, bias)\n",
    "            weights,bias = backward_propagation(X_batch, Y_batch, weights, bias, learning_rate, y_predict)\n",
    "        \n",
    "        y_train_predict = forward_propagation(train_X, weights, bias)\n",
    "        train_accuracy = accuracy(y_train_predict, train_Y)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, train acc: {train_accuracy: .4f}\")\n",
    "    \n",
    "    y_test_predict = forward_propagation(test_X, weights, bias)\n",
    "    test_accuracy = accuracy(y_test_predict, test_Y)\n",
    "    \n",
    "    print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")\n",
    "        \n",
    "        \n",
    "    #return weights,bias,train_accuracy,test_accuracy\n",
    "\n",
    "\n",
    "\n",
    "train(train_X, train_Y, test_X, test_Y, 120, 0.05, 100)\n",
    "\n",
    "            \n",
    "            "
   ],
   "id": "689e04e949dda8d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120, train acc:  0.8209\n",
      "Epoch 2/120, train acc:  0.8626\n",
      "Epoch 3/120, train acc:  0.8892\n",
      "Epoch 4/120, train acc:  0.9183\n",
      "Epoch 5/120, train acc:  0.9004\n",
      "Epoch 6/120, train acc:  0.9065\n",
      "Epoch 7/120, train acc:  0.9052\n",
      "Epoch 8/120, train acc:  0.9175\n",
      "Epoch 9/120, train acc:  0.8992\n",
      "Epoch 10/120, train acc:  0.9212\n",
      "Epoch 11/120, train acc:  0.9068\n",
      "Epoch 12/120, train acc:  0.9063\n",
      "Epoch 13/120, train acc:  0.9110\n",
      "Epoch 14/120, train acc:  0.9053\n",
      "Epoch 15/120, train acc:  0.9080\n",
      "Epoch 16/120, train acc:  0.8822\n",
      "Epoch 17/120, train acc:  0.8734\n",
      "Epoch 18/120, train acc:  0.9135\n",
      "Epoch 19/120, train acc:  0.9089\n",
      "Epoch 20/120, train acc:  0.9146\n",
      "Epoch 21/120, train acc:  0.9022\n",
      "Epoch 22/120, train acc:  0.8739\n",
      "Epoch 23/120, train acc:  0.9118\n",
      "Epoch 24/120, train acc:  0.9202\n",
      "Epoch 25/120, train acc:  0.9136\n",
      "Epoch 26/120, train acc:  0.8296\n",
      "Epoch 27/120, train acc:  0.9154\n",
      "Epoch 28/120, train acc:  0.9114\n",
      "Epoch 29/120, train acc:  0.8461\n",
      "Epoch 30/120, train acc:  0.8738\n",
      "Epoch 31/120, train acc:  0.9213\n",
      "Epoch 32/120, train acc:  0.8695\n",
      "Epoch 33/120, train acc:  0.9088\n",
      "Epoch 34/120, train acc:  0.9171\n",
      "Epoch 35/120, train acc:  0.9233\n",
      "Epoch 36/120, train acc:  0.9197\n",
      "Epoch 37/120, train acc:  0.9032\n",
      "Epoch 38/120, train acc:  0.8342\n",
      "Epoch 39/120, train acc:  0.8886\n",
      "Epoch 40/120, train acc:  0.7850\n",
      "Epoch 41/120, train acc:  0.9110\n",
      "Epoch 42/120, train acc:  0.9013\n",
      "Epoch 43/120, train acc:  0.9033\n",
      "Epoch 44/120, train acc:  0.9079\n",
      "Epoch 45/120, train acc:  0.9269\n",
      "Epoch 46/120, train acc:  0.9106\n",
      "Epoch 47/120, train acc:  0.9157\n",
      "Epoch 48/120, train acc:  0.9087\n",
      "Epoch 49/120, train acc:  0.9101\n",
      "Epoch 50/120, train acc:  0.9120\n",
      "Epoch 51/120, train acc:  0.9001\n",
      "Epoch 52/120, train acc:  0.9253\n",
      "Epoch 53/120, train acc:  0.8989\n",
      "Epoch 54/120, train acc:  0.8866\n",
      "Epoch 55/120, train acc:  0.8816\n",
      "Epoch 56/120, train acc:  0.9173\n",
      "Epoch 57/120, train acc:  0.8988\n",
      "Epoch 58/120, train acc:  0.8849\n",
      "Epoch 59/120, train acc:  0.8982\n",
      "Epoch 60/120, train acc:  0.9040\n",
      "Epoch 61/120, train acc:  0.9121\n",
      "Epoch 62/120, train acc:  0.9214\n",
      "Epoch 63/120, train acc:  0.9087\n",
      "Epoch 64/120, train acc:  0.8944\n",
      "Epoch 65/120, train acc:  0.8972\n",
      "Epoch 66/120, train acc:  0.8988\n",
      "Epoch 67/120, train acc:  0.9163\n",
      "Epoch 68/120, train acc:  0.8536\n",
      "Epoch 69/120, train acc:  0.9150\n",
      "Epoch 70/120, train acc:  0.8891\n",
      "Epoch 71/120, train acc:  0.8597\n",
      "Epoch 72/120, train acc:  0.9270\n",
      "Epoch 73/120, train acc:  0.9121\n",
      "Epoch 74/120, train acc:  0.8779\n",
      "Epoch 75/120, train acc:  0.9104\n",
      "Epoch 76/120, train acc:  0.9145\n",
      "Epoch 77/120, train acc:  0.9278\n",
      "Epoch 78/120, train acc:  0.8998\n",
      "Epoch 79/120, train acc:  0.9150\n",
      "Epoch 80/120, train acc:  0.9062\n",
      "Epoch 81/120, train acc:  0.9110\n",
      "Epoch 82/120, train acc:  0.9082\n",
      "Epoch 83/120, train acc:  0.9082\n",
      "Epoch 84/120, train acc:  0.9039\n",
      "Epoch 85/120, train acc:  0.8734\n",
      "Epoch 86/120, train acc:  0.9127\n",
      "Epoch 87/120, train acc:  0.9070\n",
      "Epoch 88/120, train acc:  0.9183\n",
      "Epoch 89/120, train acc:  0.9207\n",
      "Epoch 90/120, train acc:  0.9002\n",
      "Epoch 91/120, train acc:  0.8832\n",
      "Epoch 92/120, train acc:  0.8238\n",
      "Epoch 93/120, train acc:  0.9140\n",
      "Epoch 94/120, train acc:  0.8874\n",
      "Epoch 95/120, train acc:  0.9147\n",
      "Epoch 96/120, train acc:  0.9184\n",
      "Epoch 97/120, train acc:  0.9158\n",
      "Epoch 98/120, train acc:  0.8975\n",
      "Epoch 99/120, train acc:  0.8909\n",
      "Epoch 100/120, train acc:  0.9091\n",
      "Epoch 101/120, train acc:  0.9202\n",
      "Epoch 102/120, train acc:  0.9062\n",
      "Epoch 103/120, train acc:  0.9002\n",
      "Epoch 104/120, train acc:  0.9135\n",
      "Epoch 105/120, train acc:  0.8691\n",
      "Epoch 106/120, train acc:  0.8916\n",
      "Epoch 107/120, train acc:  0.8736\n",
      "Epoch 108/120, train acc:  0.9176\n",
      "Epoch 109/120, train acc:  0.9223\n",
      "Epoch 110/120, train acc:  0.8835\n",
      "Epoch 111/120, train acc:  0.9053\n",
      "Epoch 112/120, train acc:  0.9025\n",
      "Epoch 113/120, train acc:  0.9057\n",
      "Epoch 114/120, train acc:  0.9184\n",
      "Epoch 115/120, train acc:  0.9129\n",
      "Epoch 116/120, train acc:  0.9217\n",
      "Epoch 117/120, train acc:  0.8519\n",
      "Epoch 118/120, train acc:  0.9276\n",
      "Epoch 119/120, train acc:  0.8851\n",
      "Epoch 120/120, train acc:  0.9193\n",
      "Test accuracy: 90.71%\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bca6a78d9a49074"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
